{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Rows, Columns): (420464, 2)\n",
      "                      url label\n",
      "0  diaryofagameaddict.com   bad\n",
      "1        espdesign.com.au   bad\n",
      "2      iamagameaddict.com   bad\n",
      "3           kalantzis.net   bad\n",
      "4   slightlyoffcenter.net   bad\n",
      "Column names: Index([u'url', u'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We want to classify URLs as malicious or not. To do this, we need to know a bit about our data first.\n",
    "import pandas as pd\n",
    "\n",
    "full_data_set = pd.read_csv(\"../data/malicious_urls.csv\")\n",
    "\n",
    "# Output some information on our data\n",
    "print \"(Rows, Columns):\", full_data_set.shape\n",
    "print full_data_set.head()\n",
    "print \"Column names:\", full_data_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    0.820096\n",
       "bad     0.179904\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is incredible raw data, all we have are URLs and if there were classified as malicious or not\n",
    "# Before we create features (we'll need to create a lot of them), let's get some information on the best and worse case\n",
    "# numbers for our model\n",
    "\n",
    "# The null model simply predicts the majority case\n",
    "full_data_set['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tgerhardt/anaconda/envs/training/lib/python2.7/site-packages/ipykernel_launcher.py:20: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/tgerhardt/anaconda/envs/training/lib/python2.7/site-packages/ipykernel_launcher.py:21: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/tgerhardt/anaconda/envs/training/lib/python2.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420464, 1) (420464, 1)\n",
      "(420464, 2)\n",
      "                      url label\n",
      "0  diaryofagameaddict.com   bad\n",
      "1        espdesign.com.au   bad\n",
      "2      iamagameaddict.com   bad\n",
      "3           kalantzis.net   bad\n",
      "4   slightlyoffcenter.net   bad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99999762167510176"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: SLOW! Fitting and scoring takes a while\n",
    "\n",
    "# Based on our data, if we say that if a url is good, we'll be right 82% of the time. That's gives us a baseline\n",
    "# What's the best we can do? We'd suspect it's 100%, but this assumes that a URL has only been classified one way.\n",
    "# Let's check that assumption.\n",
    "\n",
    "# To do this easily, we'll loop through the data we're trying to predict from and create a dictionary keyed by\n",
    "# our features. We'll then store the number of times that each set of features occurred and the set of outputs\n",
    "\n",
    "# TODO: Unused. Maybe it's useful somewhere else?\n",
    "def convert_column_to_ints(column_data):\n",
    "    \"\"\" Given a PD column, convert all the values to integers \"\"\"\n",
    "    unique_values = column_data.unique()\n",
    "    replacement_dict = dict(zip(unique_values, range(len(unique_values))))\n",
    "    return column_data.map(lambda x: replacement_dict[x])\n",
    "\n",
    "def score_dataset_uniqueness(features, response):\n",
    "    \"\"\" Given a list of feature names and response names, store the \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
